{
 "metadata": {
  "name": "",
  "signature": "sha256:a7b35f86342cc0aed650141be81a33c4c04eebf4833dea962b5565e2e5daf74b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Title\n",
      "\n",
      "### Authors\n",
      "\n",
      "## Introduction\n",
      "\n",
      "### Background\n",
      "\n",
      "\"Publish or Perish\" is a common phrase in academia to emphasize the importance of frequent journal publication to improve the individual scientist's career prospects (http://en.wikipedia.org/wiki/Publish_or_perish).  A scientist is often judged by her peer-reviewed article as record of her performance in research.  \n",
      "\n",
      "However, not all authorships are created equal. \"First author\" (or \"lead author\" http://en.wikipedia.org/wiki/Lead_author) refers to the main contributor to the research that went into the publication of a research article.  In addition, publication in a prestigious academic journals is considered to be more valuable, and indicates the potential influence of the article published in it.  Another convention in biomedical journal article is the concept of \"last author\", which indicates the most senior member of the lab which has produced the paper, and it is often a faculty of the institution.  It is safe to say that at least in academia, a position as a senior member of the lab is considered to be success in a scientist's career.\n",
      "\n",
      "### Motivation\n",
      "\n",
      "There are previous studies which uses author publication records.  For example, co-authorship network is used to study the relationship of collaborations between scientists (http://www.sciencedirect.com/science/article/pii/S1751157711000630).  To our knowledge, the importance of author order has not been fully explored.  Our research will take this into consideration, with the goal of evaluating the predictive values of bibliographic records with author order to determine success in scientific careers.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Materials and Methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exploratory Data Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Munging\n",
      "\n",
      "The vast majority of the project dealt with the non-trivial extraction of relevant information (\"data munging\") of a large, imperfectly formatted dataset.  Because large data processing is not suitable for execution in iPython notebook, we have provided a small sample of the data to demonstrate how it was done."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "#### XML Parsing and Data Extraction\n",
      "2014 Medline Baseline dataset (medline14) was downloaded from National Library of Medicine (ftp.nlm.nih.gov, using leasing license for access, on November, 2014.  http://www.nlm.nih.gov/databases/journal.html).  The collection consists of a set of 746 xml files, with .gz compressed size of approximately 13 GB.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# preamble\n",
      "import os\n",
      "import codecs\n",
      "import csv\n",
      "import unicodedata\n",
      "from bs4 import BeautifulSoup\n",
      "import gzip\n",
      "from bs4 import SoupStrainer\n",
      "from collections import OrderedDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following are the support functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import codecs\n",
      "import csv\n",
      "import json\n",
      "import unicodedata\n",
      "from bs4 import BeautifulSoup\n",
      "import gzip\n",
      "from bs4 import SoupStrainer\n",
      "from collections import OrderedDict\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getFields(leafxmlfragment, fieldlist):\n",
      "    answerdict = {}\n",
      "    for field in fieldlist:\n",
      "        # get rid of unicode\n",
      "        x = bsFragment(leafxmlfragment).find_all(field)\n",
      "        if x:\n",
      "            x = x[0].string # convert to string\n",
      "            x = unicodedata.normalize('NFKD',unicode(x)).encode('ascii','ignore')\n",
      "            answerdict[field] = x\n",
      "        else:\n",
      "            answerdict[field] = ''\n",
      "    return answerdict\n",
      "\n",
      "def bsFragment(xmlfragment):\n",
      "    return BeautifulSoup(str(xmlfragment))\n",
      "\n",
      "def bs_findall(xmlfragment, *arg):\n",
      "    \"\"\"\n",
      "    Chained search isn't working for some reason, so here's a substitute.\n",
      "    usage: bs_findall(xmlfragment, 'authorlist','author')\n",
      "    finds all \"author\" under \"authorlist\"\n",
      "    returns list of author xmls in string\n",
      "    \"\"\"\n",
      "    xmlfragment = bsFragment(xmlfragment)\n",
      "    # go through nested tags to get to the last tag, collect the last tag\n",
      "    answer = []\n",
      "    if arg != ((),): # if not an empty arg\n",
      "        searchterm = arg[0]\n",
      "        for x in xmlfragment.find_all(searchterm):\n",
      "            if len(arg) > 1:\n",
      "                answer.extend(bs_findall(str(x),arg[1:] ))\n",
      "            else:\n",
      "                answer.append(str(x))\n",
      "    else:\n",
      "        return [] \n",
      "    return answer\n",
      "\n",
      "def getDate(xmlfragment):\n",
      "    # get article date\n",
      "    medlinedate_yearregex = re.compile(r'\\d+')\n",
      "    x = bs_findall(xmlfragment, 'articledate')\n",
      "    fields = 'year month day'.split()\n",
      "    x2 = getFields(x,fields)\n",
      "    if not x2['year']:\n",
      "        # \n",
      "        x = bs_findall(xmlfragment, 'MedlineDate')\n",
      "        try:\n",
      "            yr = medlinedate_yearregex.findall(getFields(x, ['medlinedate'])['medlinedate'])[0]\n",
      "        except:\n",
      "            yr = ''\n",
      "        x2 = {'year':yr, 'month':'', 'day':''}\n",
      "\n",
      "    bs_findall(xmlfragment, 'year')\n",
      "    if not x2['year']:\n",
      "        x = bs_findall(xmlfragment, 'pubdate')\n",
      "        fields = 'year month day'.split()\n",
      "        x2 = getFields(x,fields)\n",
      "    return getFields(x,fields)\n",
      "    \n",
      "\n",
      "def getAuthors(xmlfragment):\n",
      "    # extract author information\n",
      "    authordicts = []\n",
      "\n",
      "    for authorxml in bs_findall(xmlfragment, 'authorlist','author'):\n",
      "        fields = 'lastname forename initials affiliation'.split()\n",
      "        authordict = getFields(authorxml, fields)\n",
      "        authordicts.append(authordict)\n",
      "    return authordicts\n",
      "\n",
      "\n",
      "def getJournalInfo(xmlfragment):\n",
      "    # get journal info\n",
      "    fields = 'country medlineta nlmuniqueid issnlinking'.split()\n",
      "    try:\n",
      "        x = bs_findall(xmlfragment, 'medlinejournalinfo')[0]        \n",
      "    except:\n",
      "        x = \"\"\n",
      "    return getFields(x, fields)\n",
      "\n",
      "\n",
      "# consolidate all functions\n",
      "\n",
      "def processArticle(xmlfragment):\n",
      "    funcDict = dict(date=getDate, \n",
      "                    journal=getJournalInfo, \n",
      "                    authors=getAuthors)\n",
      "    answer = {}\n",
      "    for k,v in funcDict.items():\n",
      "        answer[k] = v(xmlfragment)\n",
      "    return answer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following code takes a medline xml file and extracts the information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inpath = kIn['inpath'][0]\n",
      "outpath = kIn['outpath'][0]\n",
      "\n",
      "\n",
      "# beautifulsoup doc: http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "# read a.gz file\n",
      "path = inpath # =\"/vagrant/data/medline14n0746.xml.gz\"\n",
      "f = gzip.open(path, 'rb')\n",
      "file_content = f.read()\n",
      "f.close()\n",
      "\n",
      "\n",
      "\n",
      "# split citations to chunk xml parsing (rely on closing tags as it has no other properties)\n",
      "k = file_content.split('</MedlineCitation>')\n",
      "originalfilename = os.path.split(path)[1]\n",
      "\n",
      "\n",
      "path = outpath #\"/vagrant/data/extract_medline14n0746.txt\"\n",
      "\n",
      "f = open(path, 'w')\n",
      "\n",
      "\n",
      "for entryNumber, xmlfragment in enumerate(k):\n",
      "    if entryNumber%500 == 0:\n",
      "        print \"%done:\", float(entryNumber)/float(len(k)) * 100.0, 'done', entryNumber, \"total\",  len(k)\n",
      "    entryId = \"%s:%d\"%(originalfilename, entryNumber)\n",
      "    try:\n",
      "        data = processArticle(xmlfragment)\n",
      "    except:\n",
      "        data = {}\n",
      "    data['entryid'] = entryId\n",
      "    f.write(\"%s\\n\"%str(json.dumps(data)))\n",
      "\n",
      "\n",
      "f.write(\"#done\\n\")\n",
      "f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above process was done for the entire library of 746 xml files (the resultant files had .txt extension instead of xml)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Consolidation of Author Information\n",
      "\n",
      "The resultant file had a format which included one article per row.  Because we wanted to get information about individual authors, we have transformed the format to one author per row, with multiple articles.\n",
      "\n",
      "\n",
      "##### File-wise consolidation\n",
      "\n",
      "\n",
      "\n",
      "e.g.,\n",
      "\n",
      "File_1:\n",
      "article_1: [auth_A, auth_B]\n",
      "article_2: [auth_B, auth_C]\n",
      "\n",
      "is then transformed to\n",
      "\n",
      "File_1:\n",
      "auth_A: [article_1]\n",
      "auth_B: [article_1, article_2]\n",
      "auth_C: [article_2]\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Merging of the files\n",
      "\n",
      "Unix tool was used to quickly sort and merge large files (the method was adopted from http://stackoverflow.com/questions/7693600/sort-across-multiple-files-in-linux)\n",
      "\n",
      "\n",
      "`for f in *.csv; do sort -o $f < $f; done`\n",
      "`sort --merge *.csv -o merged.txt`\n",
      "\n",
      "This ensured that \n",
      "\n",
      "`File_1:'\n",
      "`auth_A: [article_1]\n",
      "`auth_B: [article_1, article_2]\n",
      "`auth_C: [article_2]\n",
      "\n",
      "File_2:\n",
      "auth_C: [article_3]\n",
      "auth_D: [article_4]`\n",
      "\n",
      "will be transformed to\n",
      "\n",
      "`auth_A: [article_1]\n",
      "auth_B: [article_1, article_2]\n",
      "auth_C: [article_2]\n",
      "auth_C: [article_3]\n",
      "auth_D: [article_4]`\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the sorting has guaranteed that all articles by the same person is in adjacent rows, the following transformation was done:\n",
      "\n",
      "`\n",
      "auth_A: [article_1]\n",
      "auth_B: [article_1, article_2]\n",
      "auth_C: [article_2]\n",
      "auth_C: [article_3]\n",
      "auth_D: [article_4]\n",
      "`\n",
      "\n",
      "Note how rows with author C has been merged:\n",
      "\n",
      "`\n",
      "auth_A: [article_1]\n",
      "auth_B: [article_1, article_2]\n",
      "auth_C: [article_2, article_3]\n",
      "auth_D: [article_4]\n",
      "`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run as batch script\n",
      "\n",
      "import gzip, csv, os\n",
      "import ast\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "import re\n",
      "pattern = re.compile(\"([^,]*),(\\d*),[^\\[]*(\\[.*\\])[^\\]]*\")\n",
      "\n",
      "\n",
      "\n",
      "def tryfunc(xfunc, xs,  valOnException=None):\n",
      "    '''\n",
      "    Tries a function and returns valOnException on exception\n",
      "    '''\n",
      "    try:\n",
      "        return xfunc(xs)\n",
      "    except:\n",
      "        return valOnException\n",
      "\n",
      "def mean(x):\n",
      "    if x:\n",
      "        return np.average(x)\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "\n",
      "#This funciton calculates all summary Stats\n",
      "def summaryDictionary(allJournals):\n",
      "    '''\n",
      "    FFA: first first-author year:  1879.0\n",
      "    FLA: first last-author year:  1968.0\n",
      "    LAA: last all-author year:  1998.0\n",
      "    TFA: total first author paper:  28\n",
      "    TLA: total last author paper:  6\n",
      "    TAA: total paper (all author):  41\n",
      "    TCL: total career legth =  LAA - FFA:  119.0\n",
      "    FCL: faculty career length = LAA - FLA:  30.0\n",
      "    SCL: non-faculty scientist career length = TLA-FCL:  1849.0\n",
      "    TCL2: total career length = SCL + FCL:  1879.0\n",
      "    FRQFA: frequency of first author = TFA/SCL:  0.0151433207139\n",
      "    FRQTA: frequency of all authorship = TAA/TCL:  0.344537815126\n",
      "    FAEF: average first-author eigenfactor\n",
      "    MAEF: average middle-author eigenfactor\n",
      "    LAEF: average last-author eigenfactor\n",
      "    '''\n",
      "\n",
      "    pubsummary = []\n",
      "    for entry in allJournals:\n",
      "        dictEn = dict(entry)\n",
      "        year = dictEn['year']\n",
      "        if year:\n",
      "            year = float(year)        \n",
      "        isFirstAuthor = dictEn['authPos'] == 1\n",
      "        isLastAuthor  = dictEn['authPos'] == dictEn['authCount']\n",
      "        nlmuniqueid   = dictEn['nlmuniqueid']\n",
      "        affiliation   = dictEn['affiliation']\n",
      "        try:\n",
      "            ef = eigenfactordict[nlmuniqueid]\n",
      "        except:\n",
      "            ef = None\n",
      "        \n",
      "        pubsummary.append(dict(year=year,isFirstAuthor=isFirstAuthor, isLastAuthor=isLastAuthor, ef = ef, affiliation = affiliation))\n",
      "        \n",
      "    taap_total_paper              = len(pubsummary)\n",
      "    tfap_total_first_author_paper = len([x for x in pubsummary if x['isFirstAuthor']])\n",
      "    tlap_total_last_author_paper  = len([x for x in pubsummary if x['isLastAuthor']])\n",
      "    \n",
      "    # filter for publication with actual years\n",
      "    pubsummary_years = [x for x in pubsummary if x['year']]\n",
      "    \n",
      "    laay_last_all_author_paper_year    = tryfunc(max, [x['year'] for x in pubsummary_years])\n",
      "    ffay_first_first_author_paper_year = tryfunc(min, [x['year'] for x in pubsummary_years if x['isFirstAuthor']])\n",
      "    flay_first_last_author_paper_year  = tryfunc(max, [x['year'] for x in pubsummary_years if x['isLastAuthor']])\n",
      "    \n",
      "    \n",
      "    # average first author EF \n",
      "    faef_first_author_ef = mean([x['ef'] for x in pubsummary if x['isFirstAuthor'] and x['ef']])\n",
      "    # average middle author EF\n",
      "    maef_middle_author_ef = mean([x['ef'] for x in pubsummary if not x['isFirstAuthor'] and not x['isLastAuthor'] and x['ef']])\n",
      "    # average last author EF\n",
      "    laef_middle_author_ef = mean([x['ef'] for x in pubsummary if x['isLastAuthor'] and x['ef']])\n",
      "    # scientist (non-last author) ef\n",
      "    saef_all_author_ef = mean([x['ef'] for x in pubsummary if not x['isLastAuthor'] and x['ef']])\n",
      "    \n",
      "    # get list of affiliations for last-author papers\n",
      "    zaffs = ','.join(['\"\"\"%s\"\"\"'%x['affiliation'] for x in pubsummary if x['affiliation'] and x['isLastAuthor']])\n",
      "    \n",
      "    \n",
      "    # total caeer length (tcl = laay - ffay)\n",
      "    if laay_last_all_author_paper_year and ffay_first_first_author_paper_year:\n",
      "        tcl_total_career_length = laay_last_all_author_paper_year - ffay_first_first_author_paper_year\n",
      "    else:\n",
      "        tcl_total_career_length = 0\n",
      "\n",
      "    # faculty caeer length (fcl = laay - flay)\n",
      "    if laay_last_all_author_paper_year and flay_first_last_author_paper_year:\n",
      "        fcl_faculty_career_length = laay_last_all_author_paper_year - flay_first_last_author_paper_year\n",
      "    else:\n",
      "        fcl_faculty_career_length = 0\n",
      "    \n",
      "    # scientist career length\n",
      "    scl_scientist_career_length = tcl_total_career_length - fcl_faculty_career_length\n",
      "    \n",
      "    \n",
      "    #Can't divide by 0, so force the career length minimum to 1 year, (which is reasonable)\n",
      "    #change defaults here if they are not changed from above\n",
      "    if scl_scientist_career_length == 0:\n",
      "        scl_scientist_career_length = 1\n",
      "    if tcl_total_career_length == 0:\n",
      "        tcl_total_career_length = 1\n",
      "    \n",
      "    summary = dict(\n",
      "            ffay   = ffay_first_first_author_paper_year,\n",
      "            flay   = flay_first_last_author_paper_year,\n",
      "            laay   = laay_last_all_author_paper_year,\n",
      "            tfap   = tfap_total_first_author_paper,\n",
      "            tlap   = tlap_total_last_author_paper,\n",
      "            taap   = taap_total_paper,\n",
      "            tcl   = tcl_total_career_length,\n",
      "            fcl   = fcl_faculty_career_length,\n",
      "            scl   = scl_scientist_career_length,\n",
      "            frqfa = tfap_total_first_author_paper/scl_scientist_career_length,\n",
      "            frqta = taap_total_paper/tcl_total_career_length,\n",
      "            faef  = faef_first_author_ef,\n",
      "            maef  = maef_middle_author_ef,\n",
      "            laef  = laef_middle_author_ef,\n",
      "            saef  = saef_all_author_ef,\n",
      "            zaffs = zaffs,\n",
      "        )\n",
      "    return summary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "\n",
      "# get eigenfactor table\n",
      "eigenfactordict = {}\n",
      "reader = csv.reader(open(\"eigenfactor.csv\", 'r'), dialect=csv.excel)\n",
      "eigenfactordict = dict( [ (nlmuniqueid, tryfunc(float, ef))  for idx, ai, ef, issn, journal, nlmuniqueid, rank in reader if nlmuniqueid and tryfunc(float, ef)  ])\n",
      "    \n",
      "\n",
      "infileLocation = \"filtered2.txt.gz\"\n",
      "\n",
      "outfile = gzip.open(\"authorStat.txt.gz\", 'w')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# answer = []\n",
      "for idx, rawrow in enumerate(gzip.open( infileLocation, 'r'), start=1): #reader:\n",
      "#     if idx == 10000: break # limit for testing\n",
      "    if idx%10000 == 0:\n",
      "        print idx\n",
      "        \n",
      "    try:\n",
      "        author, _, raw_articles = pattern.findall(rawrow)[0]\n",
      "        sumData = summaryDictionary(ast.literal_eval(raw_articles))\n",
      "        sumData[\"author\"] = author\n",
      "        if idx == 1: # write header\n",
      "            outfile.write(\"%s\\n\"%(\",\".join(sumData.keys())))\n",
      "        if sumData['taap'] > 1 and sumData['tfap'] > 0 and sumData['scl'] > 0:\n",
      "            #answer.append(sumData)\n",
      "            outfile.write(\"%s\\n\"%(\",\".join([str(x) for x in sumData.values()])))\n",
      "    except:\n",
      "        print \"error in index %d with author %s\"%(idx, rawrow.split(',')[0])\n",
      "\n",
      "outfile.close()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Eigenfactor\n",
      "\n",
      "Eigenfactor (EF, http://www.eigenfactor.org/) was used as a free substitute for commonly used impact factor (IF, http://en.wikipedia.org/wiki/Impact_factor).\n",
      "\n",
      "In order to obtain the impact factor, the 2014 EF was \"scraped\" from the website listing (http://www.eigenfactor.org/rankings.php?bsearch=2011&searchby=year&orderby=eigenfactor&page=1)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import random\n",
      "data = []\n",
      "import urllib2\n",
      "for page in range(1,25+1):\n",
      "    url = \"http://www.eigenfactor.org/rankings.php?bsearch=2011&searchby=year&orderby=eigenfactor&page=%d\"%page\n",
      "    f = urllib2.urlopen(url)\n",
      "    x = f.read()\n",
      "    data.append(x)\n",
      "    f.close()\n",
      "    sleepsec = random.randint(2,7)\n",
      "    print \"read page %d. Sleeping for %d sec.\"%(page, sleepsec)\n",
      "    time.sleep(sleepsec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save the result:\n",
      "\n",
      "import csv\n",
      "f = open('/vagrant/cs109_firstOrPerish/data_munging/eigenRaw.csv', 'w')\n",
      "writer = csv.writer(f, dialect=csv.excel)\n",
      "for d in data:\n",
      "    writer.writerow(d)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bsFragment(xmlfragment):\n",
      "    return BeautifulSoup(str(xmlfragment))\n",
      "\n",
      "def getFields(leafxmlfragment, fieldlist):\n",
      "    \n",
      "    answerdict = {}\n",
      "    for field in fieldlist:\n",
      "        # get rid of unicode\n",
      "        x = bsFragment(leafxmlfragment).find_all(field)\n",
      "        if x:\n",
      "            x = x[0].string # convert to string\n",
      "            x = unicodedata.normalize('NFKD',unicode(x)).encode('ascii','ignore')\n",
      "            answerdict[field] = x\n",
      "        else:\n",
      "            answerdict[field] = ''\n",
      "    return answerdict\n",
      "\n",
      "def getFields(leafxmlfragment, fieldlist):\n",
      "    \n",
      "    answerdict = {}\n",
      "    for field in fieldlist:\n",
      "        # get rid of unicode\n",
      "        x = bsFragment(leafxmlfragment).find_all(field)\n",
      "        if x:\n",
      "            x = x[0].string # convert to string\n",
      "            x = unicodedata.normalize('NFKD',unicode(x)).encode('ascii','ignore')\n",
      "            answerdict[field] = x\n",
      "        else:\n",
      "            answerdict[field] = ''\n",
      "    return answerdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#http://stackoverflow.com/questions/5041008/handling-class-attribute-in-beautifulsoup\n",
      "htmfragments = []\n",
      "for d in data:\n",
      "    htmfragments.extend((BeautifulSoup(d).findAll(\"div\", { \"class\" : \"results\" }))[1:])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenfactors = [getJournalInfo(x) for x in htmfragments]\n",
      "from pandas import DataFrame\n",
      "eigenfactorsDF = DataFrame(eigenfactors)\n",
      "eigenfactorsDF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, medline_uniqueID was recorded.  So we extracted the issn to nlmuniqueid mapping table from "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "def jsonLoads(jsonString):\n",
      "    '''\n",
      "    # helper function to convert unicode to str\n",
      "    # used to decode SOAP reply\n",
      "    # http://stackoverflow.com/questions/956867/how-to-get-string-objects-instead-of-unicode-ones-from-json-in-python\n",
      "\n",
      "    replace:\n",
      "        json.loads(result.PE_executeResponse.Response, object_hook=decode_dict)\n",
      "    with:\n",
      "        jsonLoads(result.PE_executeResponse.Response)\n",
      "    '''\n",
      "    def _decode_list(data):\n",
      "        rv = []\n",
      "        for item in data:\n",
      "            if isinstance(item, unicode):\n",
      "                item = item.encode('utf-8')\n",
      "            elif isinstance(item, list):\n",
      "                item = _decode_list(item)\n",
      "            elif isinstance(item, dict):\n",
      "                item = _decode_dict(item)\n",
      "            rv.append(item)\n",
      "        return rv\n",
      "\n",
      "    def _decode_dict(data):\n",
      "        rv = {}\n",
      "        for key, value in data.iteritems():\n",
      "            if isinstance(key, unicode):\n",
      "                key = key.encode('utf-8')\n",
      "            if isinstance(value, unicode):\n",
      "                value = value.encode('utf-8')\n",
      "            elif isinstance(value, list):\n",
      "                value = _decode_list(value)\n",
      "            elif isinstance(value, dict):\n",
      "                value = _decode_dict(value)\n",
      "            rv[key] = value\n",
      "        return rv\n",
      "    return json.loads(jsonString, object_hook=_decode_dict)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import os\n",
      "# source: http://stackoverflow.com/questions/9816816/relative-and-absolute-paths-of-all-files\n",
      "\n",
      "def absoluteFilePaths(directory):\n",
      "   for dirpath,_,filenames in os.walk(directory):\n",
      "       for f in filenames:\n",
      "           yield os.path.abspath(os.path.join(dirpath, f))\n",
      "\n",
      "def getIssnDict(infile):\n",
      "    f = open(infile, 'r')\n",
      "    data = f.readlines()\n",
      "    f.close()\n",
      "\n",
      "    answer = {}\n",
      "    for d in data:\n",
      "        try:\n",
      "            k = jsonLoads(d)['journal']\n",
      "            answer[ k['issnlinking'] ]  = k['nlmuniqueid']\n",
      "        except:\n",
      "            pass\n",
      "    return answer\n",
      "\n",
      "answer = {}\n",
      "indirectory = '/vagrant/cs109_firstOrPerish/data_munging/outfile_version2/'\n",
      "for infile in absoluteFilePaths(indirectory):\n",
      "    print \"updating with: \", infile[len(indirectory)+1:]\n",
      "    answer.update(getIssnDict(infile))\n",
      "issnDict = answer\n",
      "\n",
      "\n",
      "# map issn to nlmuniqueid\n",
      "x = []\n",
      "for issn, nlm in issnDict.items():\n",
      "    x.append( dict(issn=issn, nlmuniqueid=nlm))\n",
      "xx = DataFrame(x)\n",
      "xx.to_csv(\"/vagrant/cs109_firstOrPerish/data_munging/issn_nlmuniqueid.csv\")\n",
      "xx\n",
      "\n",
      "\n",
      "issnDict.keys()[1]\n",
      "\n",
      "for efrow in eigenfactors:\n",
      "    nui = ''\n",
      "    if efrow['issn'].strip() in issnDict.keys():\n",
      "        nui = issnDict[efrow['issn'].strip()]\n",
      "    efrow['nlmuniqueid'] = nui\n",
      "\n",
      "\n",
      "from pandas import DataFrame\n",
      "\n",
      "\n",
      "eigenfactorsDF = DataFrame(eigenfactors)\n",
      "eigenfactorsDF\n",
      "\n",
      "\n",
      "\n",
      "# eigenfactorsDF.to_csv(\"/vagrant/cs109_firstOrPerish/data_munging/eigenfactor.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Affiliated Institutions\n",
      "\n",
      "Institution salaries were also scraped off of an article"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# preamble\n",
      "import os\n",
      "import codecs\n",
      "import csv\n",
      "import unicodedata\n",
      "from bs4 import BeautifulSoup\n",
      "import gzip\n",
      "from bs4 import SoupStrainer\n",
      "from collections import OrderedDict\n",
      "import json\n",
      "import re\n",
      "\n",
      "import pandas as pd\n",
      "from pandas import DataFrame\n",
      "f = open(\"data/aaup_faculty_salary_survey_results_raw.txt\")\n",
      "rawdata = f.readlines()\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To obtain the raw text, I have simply copied and pasted each page into a text editor.\n",
      "\n",
      "Below, I've created a simple parser, which locates the beginning and end of individual table pages in the copied text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "header = \"College\tFull professors\tAssociate professors\tAssistant professors\tInstructors\tStudent-fac. ratio\"\n",
      "rules = [{'pattern':header, \n",
      "          'result':True}, \n",
      "         {'pattern':r\"Showing \\d+\u2013\\d+ of [\\d\\,]+ colleges\", \n",
      "          'result':False}]\n",
      "\n",
      "def applyMatchRules(state, rules, s):\n",
      "    ''' pattern matching function '''\n",
      "    for rule in rules:\n",
      "        if re.search(rule['pattern'], s):\n",
      "            return rule['result']\n",
      "    return state\n",
      "\n",
      "\n",
      "answer = []\n",
      "state = False\n",
      "for row in rawdata:\n",
      "    case = (state, applyMatchRules(state,rules,row))\n",
      "    if   (False, True) == case: \n",
      "        state = True\n",
      "    elif (True, False) == case: \n",
      "        state = False\n",
      "    elif state == True:\n",
      "        answer.append(dict(zip(header.split('\\t'), row.replace('\\n','').split('\\t'))))\n",
      "\n",
      "\n",
      "sfratio = \"Student-fac. ratio\"\n",
      "faculties = \"Assistant professors\tAssociate professors\tFull professors\tInstructors\".split('\\t')\n",
      "\n",
      "\n",
      "def toInt(x):\n",
      "    if x == '':\n",
      "        return None\n",
      "    else:\n",
      "        return int(x)\n",
      "\n",
      "# hint to replace $ and ,\n",
      "# http://stackoverflow.com/questions/17667606/efficiently-converting-strings-to-appropriate-numeric-types-in-pandas-dataframe\n",
      "facsaldf = DataFrame(answer)\n",
      "for faculty in faculties:\n",
      "    \n",
      "    facsaldf[faculty] = [toInt(x) for x in list(facsaldf[faculty].str.replace(r'[$,]', ''))] #facsaldf[faculty].str.replace(r'[$,]', '')\n",
      "\n",
      "# facsaldf.to_dict()\n",
      "\n",
      "\n",
      "# list(facsaldf[faculty].str.replace(r'[$,]', ''))\n",
      "facsaldf.to_csv('data/faculty_salary_2012.csv')\n",
      "facsaldf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assistant professors</th>\n",
        "      <th>Associate professors</th>\n",
        "      <th>College</th>\n",
        "      <th>Full professors</th>\n",
        "      <th>Instructors</th>\n",
        "      <th>Student-fac. ratio</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0   </th>\n",
        "      <td> 109800</td>\n",
        "      <td> 120900</td>\n",
        "      <td>                                Harvard University</td>\n",
        "      <td> 198400</td>\n",
        "      <td>  56700</td>\n",
        "      <td>  7 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1   </th>\n",
        "      <td> 102300</td>\n",
        "      <td> 114200</td>\n",
        "      <td>                             University of Chicago</td>\n",
        "      <td> 198200</td>\n",
        "      <td>  60100</td>\n",
        "      <td>  6 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2   </th>\n",
        "      <td>  99000</td>\n",
        "      <td> 125000</td>\n",
        "      <td>                               Columbia University</td>\n",
        "      <td> 197800</td>\n",
        "      <td> 129600</td>\n",
        "      <td>  6 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3   </th>\n",
        "      <td> 109800</td>\n",
        "      <td> 131200</td>\n",
        "      <td>                               Stanford University</td>\n",
        "      <td> 195400</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 10 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4   </th>\n",
        "      <td>  94200</td>\n",
        "      <td> 123700</td>\n",
        "      <td>                              Princeton University</td>\n",
        "      <td> 193800</td>\n",
        "      <td>  76800</td>\n",
        "      <td>  6 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5   </th>\n",
        "      <td>  99700</td>\n",
        "      <td> 106100</td>\n",
        "      <td>                               New York University</td>\n",
        "      <td> 182400</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 11 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6   </th>\n",
        "      <td> 112300</td>\n",
        "      <td> 117800</td>\n",
        "      <td>                        University of Pennsylvania</td>\n",
        "      <td> 181600</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  6 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7   </th>\n",
        "      <td>  89700</td>\n",
        "      <td> 108600</td>\n",
        "      <td>                                   Yale University</td>\n",
        "      <td> 180400</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  6 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8   </th>\n",
        "      <td>  96000</td>\n",
        "      <td> 114500</td>\n",
        "      <td>                                   Duke University</td>\n",
        "      <td> 175300</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  8 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9   </th>\n",
        "      <td> 111300</td>\n",
        "      <td> 121300</td>\n",
        "      <td>                California Institute of Technology</td>\n",
        "      <td> 175000</td>\n",
        "      <td>  45300</td>\n",
        "      <td>  3 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10  </th>\n",
        "      <td>  96800</td>\n",
        "      <td> 100200</td>\n",
        "      <td>                Washington University in St. Louis</td>\n",
        "      <td> 172400</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  7 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11  </th>\n",
        "      <td>  98900</td>\n",
        "      <td> 110200</td>\n",
        "      <td>                           Northwestern University</td>\n",
        "      <td> 172100</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  7 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12  </th>\n",
        "      <td> 102800</td>\n",
        "      <td> 120300</td>\n",
        "      <td>             Massachusetts Institute of Technology</td>\n",
        "      <td> 171800</td>\n",
        "      <td>  57100</td>\n",
        "      <td>  8 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13  </th>\n",
        "      <td>  89700</td>\n",
        "      <td> 107300</td>\n",
        "      <td>                                Yeshiva University</td>\n",
        "      <td> 170900</td>\n",
        "      <td>  63600</td>\n",
        "      <td>  6 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14  </th>\n",
        "      <td> 100000</td>\n",
        "      <td> 125600</td>\n",
        "      <td>                                    Babson College</td>\n",
        "      <td> 167300</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 14 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15  </th>\n",
        "      <td>  94400</td>\n",
        "      <td> 109000</td>\n",
        "      <td>                             Georgetown University</td>\n",
        "      <td> 167100</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 11 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16  </th>\n",
        "      <td>  89900</td>\n",
        "      <td> 120200</td>\n",
        "      <td>                New Jersey Institute of Technology</td>\n",
        "      <td> 166600</td>\n",
        "      <td>  79000</td>\n",
        "      <td> 15 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17  </th>\n",
        "      <td>  87400</td>\n",
        "      <td> 107400</td>\n",
        "      <td>           University of California at Los Angeles</td>\n",
        "      <td> 162600</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 16 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18  </th>\n",
        "      <td>  89700</td>\n",
        "      <td> 108500</td>\n",
        "      <td>                                 Dartmouth College</td>\n",
        "      <td> 162100</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  8 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19  </th>\n",
        "      <td>  97000</td>\n",
        "      <td> 113000</td>\n",
        "      <td>                                Cornell University</td>\n",
        "      <td> 161800</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 12 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20  </th>\n",
        "      <td>  86600</td>\n",
        "      <td> 106000</td>\n",
        "      <td>                                   Rice University</td>\n",
        "      <td> 159500</td>\n",
        "      <td>  54800</td>\n",
        "      <td>  8 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21  </th>\n",
        "      <td>  76500</td>\n",
        "      <td>  98600</td>\n",
        "      <td>                             Vanderbilt University</td>\n",
        "      <td> 158300</td>\n",
        "      <td>  55300</td>\n",
        "      <td>  8 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22  </th>\n",
        "      <td>  86500</td>\n",
        "      <td> 101600</td>\n",
        "      <td>                                  Emory University</td>\n",
        "      <td> 158000</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  7 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23  </th>\n",
        "      <td>  82300</td>\n",
        "      <td>  99300</td>\n",
        "      <td>                                  Brown University</td>\n",
        "      <td> 156700</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  9 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24  </th>\n",
        "      <td>  75000</td>\n",
        "      <td> 101300</td>\n",
        "      <td>                               American University</td>\n",
        "      <td> 156100</td>\n",
        "      <td>  50400</td>\n",
        "      <td> 13 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25  </th>\n",
        "      <td>  93300</td>\n",
        "      <td> 105300</td>\n",
        "      <td>                 University of Southern California</td>\n",
        "      <td> 155900</td>\n",
        "      <td>  66600</td>\n",
        "      <td>  9 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26  </th>\n",
        "      <td>  86100</td>\n",
        "      <td>  99700</td>\n",
        "      <td>                                    Boston College</td>\n",
        "      <td> 154300</td>\n",
        "      <td>  82800</td>\n",
        "      <td> 16 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27  </th>\n",
        "      <td>  92300</td>\n",
        "      <td> 104600</td>\n",
        "      <td>              University of California at Berkeley</td>\n",
        "      <td> 154000</td>\n",
        "      <td>  44600</td>\n",
        "      <td> 16 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28  </th>\n",
        "      <td>  84200</td>\n",
        "      <td> 103100</td>\n",
        "      <td>                      George Washington University</td>\n",
        "      <td> 152000</td>\n",
        "      <td>  62400</td>\n",
        "      <td> 13 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29  </th>\n",
        "      <td>  87800</td>\n",
        "      <td> 105000</td>\n",
        "      <td>                                 Boston University</td>\n",
        "      <td> 151700</td>\n",
        "      <td>  53300</td>\n",
        "      <td> 13 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1255</th>\n",
        "      <td>  54400</td>\n",
        "      <td>  65000</td>\n",
        "      <td>                Kent State University at Ashtabula</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 20 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1256</th>\n",
        "      <td>  58400</td>\n",
        "      <td>  67000</td>\n",
        "      <td>              Kent State University-East Liverpool</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 17 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1257</th>\n",
        "      <td>  59300</td>\n",
        "      <td>  71200</td>\n",
        "      <td>                       Kent State University-Salem</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 18 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1258</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>  71100</td>\n",
        "      <td>                      Kent State University-Geauga</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 18 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1259</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>  67700</td>\n",
        "      <td>                    Ohio University Eastern Campus</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 22 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1260</th>\n",
        "      <td>  53200</td>\n",
        "      <td>  67500</td>\n",
        "      <td>                   Ohio University Southern Campus</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 27 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1261</th>\n",
        "      <td>  54200</td>\n",
        "      <td>  67800</td>\n",
        "      <td>                  Ohio University Lancaster Campus</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 26 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1262</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>             Oklahoma State University at Okmulgee</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 18 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1263</th>\n",
        "      <td>  55100</td>\n",
        "      <td>  56500</td>\n",
        "      <td>            University of Pittsburgh at Titusville</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  47400</td>\n",
        "      <td> 12 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1264</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                           Aiken Technical College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 18 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1265</th>\n",
        "      <td>  45700</td>\n",
        "      <td>  47100</td>\n",
        "      <td>         University of South Carolina-Salkehatchie</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  38100</td>\n",
        "      <td> 25 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1266</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>             University of South Carolina at Union</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 19 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1267</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                     Spartanburg Methodist College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 19 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1268</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                                     Blinn College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 26 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1269</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                             Central Texas College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 12 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1270</th>\n",
        "      <td>  53400</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                        Lamar State College-Orange</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  40300</td>\n",
        "      <td> 19 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1271</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                                    Vernon College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 16 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1272</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                                  Marlboro College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  8 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1273</th>\n",
        "      <td>  47200</td>\n",
        "      <td>  60700</td>\n",
        "      <td>             Dabney S. Lancaster Community College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  56600</td>\n",
        "      <td> 18 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1274</th>\n",
        "      <td>  49700</td>\n",
        "      <td>  56100</td>\n",
        "      <td>                   Eastern Shore Community College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 15 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1275</th>\n",
        "      <td>  51200</td>\n",
        "      <td>  56800</td>\n",
        "      <td>                    Rappahannock Community College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>  48800</td>\n",
        "      <td> 22 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1276</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                                     Clark College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 17 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1277</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                           Evergreen State College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 23 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1278</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                          Wenatchee Valley College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 20 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1279</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                          DeKalb Technical College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 27 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1280</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>              NorthWest Arkansas Community College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 19 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1281</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>          Fond du Lac Tribal and Community College</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 27 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1282</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>         Metropolitan Community College Blue River</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 20 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1283</th>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> Metropolitan Community College-Business and Te...</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 11 to 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1284</th>\n",
        "      <td>  46100</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> Shorter University, College of Professional St...</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 25 to 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>1285 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "      Assistant professors  Associate professors  \\\n",
        "0                   109800                120900   \n",
        "1                   102300                114200   \n",
        "2                    99000                125000   \n",
        "3                   109800                131200   \n",
        "4                    94200                123700   \n",
        "5                    99700                106100   \n",
        "6                   112300                117800   \n",
        "7                    89700                108600   \n",
        "8                    96000                114500   \n",
        "9                   111300                121300   \n",
        "10                   96800                100200   \n",
        "11                   98900                110200   \n",
        "12                  102800                120300   \n",
        "13                   89700                107300   \n",
        "14                  100000                125600   \n",
        "15                   94400                109000   \n",
        "16                   89900                120200   \n",
        "17                   87400                107400   \n",
        "18                   89700                108500   \n",
        "19                   97000                113000   \n",
        "20                   86600                106000   \n",
        "21                   76500                 98600   \n",
        "22                   86500                101600   \n",
        "23                   82300                 99300   \n",
        "24                   75000                101300   \n",
        "25                   93300                105300   \n",
        "26                   86100                 99700   \n",
        "27                   92300                104600   \n",
        "28                   84200                103100   \n",
        "29                   87800                105000   \n",
        "...                    ...                   ...   \n",
        "1255                 54400                 65000   \n",
        "1256                 58400                 67000   \n",
        "1257                 59300                 71200   \n",
        "1258                   NaN                 71100   \n",
        "1259                   NaN                 67700   \n",
        "1260                 53200                 67500   \n",
        "1261                 54200                 67800   \n",
        "1262                   NaN                   NaN   \n",
        "1263                 55100                 56500   \n",
        "1264                   NaN                   NaN   \n",
        "1265                 45700                 47100   \n",
        "1266                   NaN                   NaN   \n",
        "1267                   NaN                   NaN   \n",
        "1268                   NaN                   NaN   \n",
        "1269                   NaN                   NaN   \n",
        "1270                 53400                   NaN   \n",
        "1271                   NaN                   NaN   \n",
        "1272                   NaN                   NaN   \n",
        "1273                 47200                 60700   \n",
        "1274                 49700                 56100   \n",
        "1275                 51200                 56800   \n",
        "1276                   NaN                   NaN   \n",
        "1277                   NaN                   NaN   \n",
        "1278                   NaN                   NaN   \n",
        "1279                   NaN                   NaN   \n",
        "1280                   NaN                   NaN   \n",
        "1281                   NaN                   NaN   \n",
        "1282                   NaN                   NaN   \n",
        "1283                   NaN                   NaN   \n",
        "1284                 46100                   NaN   \n",
        "\n",
        "                                                College  Full professors  \\\n",
        "0                                    Harvard University           198400   \n",
        "1                                 University of Chicago           198200   \n",
        "2                                   Columbia University           197800   \n",
        "3                                   Stanford University           195400   \n",
        "4                                  Princeton University           193800   \n",
        "5                                   New York University           182400   \n",
        "6                            University of Pennsylvania           181600   \n",
        "7                                       Yale University           180400   \n",
        "8                                       Duke University           175300   \n",
        "9                    California Institute of Technology           175000   \n",
        "10                   Washington University in St. Louis           172400   \n",
        "11                              Northwestern University           172100   \n",
        "12                Massachusetts Institute of Technology           171800   \n",
        "13                                   Yeshiva University           170900   \n",
        "14                                       Babson College           167300   \n",
        "15                                Georgetown University           167100   \n",
        "16                   New Jersey Institute of Technology           166600   \n",
        "17              University of California at Los Angeles           162600   \n",
        "18                                    Dartmouth College           162100   \n",
        "19                                   Cornell University           161800   \n",
        "20                                      Rice University           159500   \n",
        "21                                Vanderbilt University           158300   \n",
        "22                                     Emory University           158000   \n",
        "23                                     Brown University           156700   \n",
        "24                                  American University           156100   \n",
        "25                    University of Southern California           155900   \n",
        "26                                       Boston College           154300   \n",
        "27                 University of California at Berkeley           154000   \n",
        "28                         George Washington University           152000   \n",
        "29                                    Boston University           151700   \n",
        "...                                                 ...              ...   \n",
        "1255                 Kent State University at Ashtabula              NaN   \n",
        "1256               Kent State University-East Liverpool              NaN   \n",
        "1257                        Kent State University-Salem              NaN   \n",
        "1258                       Kent State University-Geauga              NaN   \n",
        "1259                     Ohio University Eastern Campus              NaN   \n",
        "1260                    Ohio University Southern Campus              NaN   \n",
        "1261                   Ohio University Lancaster Campus              NaN   \n",
        "1262              Oklahoma State University at Okmulgee              NaN   \n",
        "1263             University of Pittsburgh at Titusville              NaN   \n",
        "1264                            Aiken Technical College              NaN   \n",
        "1265          University of South Carolina-Salkehatchie              NaN   \n",
        "1266              University of South Carolina at Union              NaN   \n",
        "1267                      Spartanburg Methodist College              NaN   \n",
        "1268                                      Blinn College              NaN   \n",
        "1269                              Central Texas College              NaN   \n",
        "1270                         Lamar State College-Orange              NaN   \n",
        "1271                                     Vernon College              NaN   \n",
        "1272                                   Marlboro College              NaN   \n",
        "1273              Dabney S. Lancaster Community College              NaN   \n",
        "1274                    Eastern Shore Community College              NaN   \n",
        "1275                     Rappahannock Community College              NaN   \n",
        "1276                                      Clark College              NaN   \n",
        "1277                            Evergreen State College              NaN   \n",
        "1278                           Wenatchee Valley College              NaN   \n",
        "1279                           DeKalb Technical College              NaN   \n",
        "1280               NorthWest Arkansas Community College              NaN   \n",
        "1281           Fond du Lac Tribal and Community College              NaN   \n",
        "1282          Metropolitan Community College Blue River              NaN   \n",
        "1283  Metropolitan Community College-Business and Te...              NaN   \n",
        "1284  Shorter University, College of Professional St...              NaN   \n",
        "\n",
        "      Instructors Student-fac. ratio  \n",
        "0           56700             7 to 1  \n",
        "1           60100             6 to 1  \n",
        "2          129600             6 to 1  \n",
        "3             NaN            10 to 1  \n",
        "4           76800             6 to 1  \n",
        "5             NaN            11 to 1  \n",
        "6             NaN             6 to 1  \n",
        "7             NaN             6 to 1  \n",
        "8             NaN             8 to 1  \n",
        "9           45300             3 to 1  \n",
        "10            NaN             7 to 1  \n",
        "11            NaN             7 to 1  \n",
        "12          57100             8 to 1  \n",
        "13          63600             6 to 1  \n",
        "14            NaN            14 to 1  \n",
        "15            NaN            11 to 1  \n",
        "16          79000            15 to 1  \n",
        "17            NaN            16 to 1  \n",
        "18            NaN             8 to 1  \n",
        "19            NaN            12 to 1  \n",
        "20          54800             8 to 1  \n",
        "21          55300             8 to 1  \n",
        "22            NaN             7 to 1  \n",
        "23            NaN             9 to 1  \n",
        "24          50400            13 to 1  \n",
        "25          66600             9 to 1  \n",
        "26          82800            16 to 1  \n",
        "27          44600            16 to 1  \n",
        "28          62400            13 to 1  \n",
        "29          53300            13 to 1  \n",
        "...           ...                ...  \n",
        "1255          NaN            20 to 1  \n",
        "1256          NaN            17 to 1  \n",
        "1257          NaN            18 to 1  \n",
        "1258          NaN            18 to 1  \n",
        "1259          NaN            22 to 1  \n",
        "1260          NaN            27 to 1  \n",
        "1261          NaN            26 to 1  \n",
        "1262          NaN            18 to 1  \n",
        "1263        47400            12 to 1  \n",
        "1264          NaN            18 to 1  \n",
        "1265        38100            25 to 1  \n",
        "1266          NaN            19 to 1  \n",
        "1267          NaN            19 to 1  \n",
        "1268          NaN            26 to 1  \n",
        "1269          NaN            12 to 1  \n",
        "1270        40300            19 to 1  \n",
        "1271          NaN            16 to 1  \n",
        "1272          NaN             8 to 1  \n",
        "1273        56600            18 to 1  \n",
        "1274          NaN            15 to 1  \n",
        "1275        48800            22 to 1  \n",
        "1276          NaN            17 to 1  \n",
        "1277          NaN            23 to 1  \n",
        "1278          NaN            20 to 1  \n",
        "1279          NaN            27 to 1  \n",
        "1280          NaN            19 to 1  \n",
        "1281          NaN            27 to 1  \n",
        "1282          NaN            20 to 1  \n",
        "1283          NaN            11 to 1  \n",
        "1284          NaN            25 to 1  \n",
        "\n",
        "[1285 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Matching the college name to the affiliation column was a time-consuming manual task, spanning multiple days.  The following steps were taken to clean the data (using various tools like text editors):\n",
      "\n",
      "1. Select out US institutions via keywords like 'U.S.A.'\n",
      "2. Use regular expression to take the last comma-delimited text:  (.*\\,\\s+([^\\,]+)\\.)'\n",
      "3. Use regular expression to get the top-level domain of an email address: .*(\\@.*(\\.[a-zA-Z]+).*)\\\n",
      "4. Filter out rows with foreign top-level domain (e.g., .au, .jp, .de).  The top-level domains were taken from this table(http://en.wikipedia.org/wiki/List_of_Internet_top-level_domains)\n",
      "5. Use foreign country names (http://en.wikipedia.org/wiki/List_of_Internet_top-level_domains) and filter out based on wildcard search.\n",
      "6. Visually inspect and find keywords which escaped the foreign country filters (e.g., tokyo, london, vancouver, taipei, taiwan, korea, iran, espana, madrid, venezuela, brasil, janeiro, aires, guadalajara, etc.)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "metadata": {
  "name": "",
  "signature": "sha256:8abfc8301513d1536f0c3927441088ac80f3d3c5b2a33c607e1f0453d6813cd7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# preamble\n",
      "import os\n",
      "import codecs\n",
      "import csv\n",
      "import unicodedata\n",
      "from bs4 import BeautifulSoup\n",
      "import gzip\n",
      "from bs4 import SoupStrainer\n",
      "from collections import OrderedDict\n",
      "import json\n",
      "import pandas as pd\n",
      "\n",
      "def jsonLoads(jsonString):\n",
      "    '''\n",
      "    # helper function to convert unicode to str\n",
      "    # used to decode SOAP reply\n",
      "    # http://stackoverflow.com/questions/956867/how-to-get-string-objects-instead-of-unicode-ones-from-json-in-python\n",
      "\n",
      "    replace:\n",
      "        json.loads(result.PE_executeResponse.Response, object_hook=decode_dict)\n",
      "    with:\n",
      "        jsonLoads(result.PE_executeResponse.Response)\n",
      "    '''\n",
      "    def _decode_list(data):\n",
      "        rv = []\n",
      "        for item in data:\n",
      "            if isinstance(item, unicode):\n",
      "                item = item.encode('utf-8')\n",
      "            elif isinstance(item, list):\n",
      "                item = _decode_list(item)\n",
      "            elif isinstance(item, dict):\n",
      "                item = _decode_dict(item)\n",
      "            rv.append(item)\n",
      "        return rv\n",
      "\n",
      "    def _decode_dict(data):\n",
      "        rv = {}\n",
      "        for key, value in data.iteritems():\n",
      "            if isinstance(key, unicode):\n",
      "                key = key.encode('utf-8')\n",
      "            if isinstance(value, unicode):\n",
      "                value = value.encode('utf-8')\n",
      "            elif isinstance(value, list):\n",
      "                value = _decode_list(value)\n",
      "            elif isinstance(value, dict):\n",
      "                value = _decode_dict(value)\n",
      "            rv[key] = value\n",
      "        return rv\n",
      "    return json.loads(jsonString, object_hook=_decode_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#f = open(\"../../../../../Desktop/outfile/outfile/medline14n0685.txt\", 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allFiles = []\n",
      "for file in os.listdir(\"../../../../../Desktop/outfile2_partial/outfile2/\"):\n",
      "    if file.endswith(\".txt\"):\n",
      "        allFiles.append(file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print allFiles[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['medline14n0003.txt', 'medline14n0004.txt', 'medline14n0005.txt', 'medline14n0006.txt', 'medline14n0007.txt', 'medline14n0008.txt', 'medline14n0009.txt', 'medline14n0010.txt', 'medline14n0011.txt', 'medline14n0012.txt', 'medline14n0013.txt', 'medline14n0014.txt', 'medline14n0015.txt', 'medline14n0016.txt', 'medline14n0017.txt', 'medline14n0018.txt', 'medline14n0019.txt', 'medline14n0020.txt', 'medline14n0021.txt', 'medline14n0022.txt']\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = f.readlines()\n",
      "#f.close"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#d = data[15]\n",
      "#d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print d[1:2]\n",
      "\n",
      "#print jsonData\n",
      "#jsonData = json.dumps(jsonData)\n",
      "\n",
      "#print jsonData\n",
      "\n",
      "#d2 = jsonLoads(d)\n",
      "#date    = d2['date'] \n",
      "#journal = d2['journal']\n",
      "#authors = d2['authors']\n",
      "#entryid = d2['entryid']\n",
      "\n",
      "#print date\n",
      "#print journal\n",
      "#print authors\n",
      "#print entryid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'year': '2011', 'day': '15', 'month': '04'}\n",
        "{'medlineta': 'J Nucl Med', 'country': 'United States', 'nlmuniqueid': '0217410', 'issnlinking': '0161-5505'}\n",
        "[{'affiliation': 'Department of Neurology, Faculty of Medicine and University Clinic, Heinrich Heine University, Dusseldorf, Germany. martin.suedmeyer@uni-duesseldorf.de', 'initials': 'M', 'lastname': 'Sudmeyer', 'forename': 'Martin'}, {'affiliation': '', 'initials': 'C', 'lastname': 'Antke', 'forename': 'Christina'}, {'affiliation': '', 'initials': 'T', 'lastname': 'Zizek', 'forename': 'Tanja'}, {'affiliation': '', 'initials': 'M', 'lastname': 'Beu', 'forename': 'Markus'}, {'affiliation': '', 'initials': 'S', 'lastname': 'Nikolaus', 'forename': 'Susanne'}, {'affiliation': '', 'initials': 'L', 'lastname': 'Wojtecki', 'forename': 'Lars'}, {'affiliation': '', 'initials': 'A', 'lastname': 'Schnitzler', 'forename': 'Alfons'}, {'affiliation': '', 'initials': 'HW', 'lastname': 'Muller', 'forename': 'Hans-Wilhelm'}]\n",
        "medline14n0685.xml.gz:15\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def newAuthorOnlyRow(authorName, journalInfo, position, total ):\n",
      "    journalInfo['authPosition'] = str(position) + ','+ str(total)\n",
      "    row = {'author': authorName, 'journals':[journalInfo] }\n",
      "    return row\n",
      "    \n",
      "def authorExisting(processedAuthor, author):\n",
      "    exists = True\n",
      "    \n",
      "    for existingAuth in processedAuthor:\n",
      "        if existingAuth == author:\n",
      "            exists = False\n",
      "            break\n",
      "    return exists\n",
      "\n",
      "def journalSet(data):\n",
      "    journal = data['journal']\n",
      "    return journal\n",
      "\n",
      "def getAuthorInfo(d2, authorData, authorDF, count):\n",
      "    if 'authors' in d2.keys():\n",
      "        authors = d2['authors']\n",
      "        if authors:\n",
      "            authPosition = 0\n",
      "            authorsCount = len(authors)\n",
      "            firstAffiliation = authors[0]['affiliation']\n",
      "            #print \"Num of Authors: \", authorsCount \n",
      "            processedAuthor = []\n",
      "            for author in authors:\n",
      "                authPosition +=1\n",
      "                #jounral = ''\n",
      "                if author['lastname']:\n",
      "                    temp = journalSet(d2)\n",
      "                    journal = dict(temp)\n",
      "                    journal['date'] = d2['date']\n",
      "                    #print \"Journal: \" , journal\n",
      "                    #print authors[0]\n",
      "                    authorKey = author['forename'] + author['lastname']\n",
      "                    authorKey = authorKey.replace(\" \", \"\").lower()\n",
      "                    #print authorKey\n",
      "                    #journal[authPosition]['authPosition'] = str(authPosition) + ','+ str(authorsCount)\n",
      "                    #print journal[authPosition]['authPosition'] \n",
      "                    if author['affiliation']:\n",
      "                        journal['affiliation'] = author['affiliation']\n",
      "                    else:\n",
      "                        journal['affiliation']= firstAffiliation\n",
      "                    #print authorData\n",
      "\n",
      "                    #print count\n",
      "                    if count == 0 or not authorData :\n",
      "                        #print \"processedAuthor\"\n",
      "                        if authorExisting(processedAuthor, authorKey):\n",
      "                            authorRow = newAuthorOnlyRow(authorKey, journal, authPosition, authorsCount)\n",
      "                            authorData.append(authorRow)\n",
      "                    else:\n",
      "                        try:\n",
      "                            if authorDF[authorDF['author'] == authorKey].empty:\n",
      "                                if authorExisting(processedAuthor, authorKey):\n",
      "                                    authorRow = newAuthorOnlyRow(authorKey, journal, authPosition, authorsCount)\n",
      "                                    authorData.append(authorRow)\n",
      "                            else:\n",
      "                                #print \"Duplicate\"\n",
      "                                if authorExisting(processedAuthor, authorKey):\n",
      "                                    journal['authPosition'] = str(authPosition) + ','+ str(authorsCount)\n",
      "                                    authorData[authorDF[authorDF['author'] == authorKey].index]['journals'].append(journal)\n",
      "                        except:\n",
      "                            print \"Except thrown: \", journal , \" :Author: \" , authorKey , \" :Count: \" , count\n",
      "                        #    authorRow = newAuthorOnlyRow(authorKey, journal)\n",
      "                        #    authorData.append(authorRow)\n",
      "#                    print authorData\n",
      "                    processedAuthor.append(authorKey)\n",
      "            # returns concat_names, author_number, author_count\n",
      "            return\n",
      "    else:\n",
      "        return []\n",
      "#subData = data\n",
      "#subData = data[:1]\n",
      "#print len(subData)\n",
      "for fileName in allFiles[:20]:\n",
      "    print \"Processing file: \" + fileName\n",
      "    f = open(\"../../../../../Desktop/outfile2_partial/outfile2/\"+fileName, 'r')\n",
      "    data = f.readlines()\n",
      "    f.close\n",
      "    count = 0\n",
      "    authorDF = []\n",
      "    authorData = []\n",
      "    subData = data\n",
      "    print \"Start: Processing \", len(subData) , \" records\"\n",
      "    for d2 in subData:\n",
      "\n",
      "        if authorData:\n",
      "            authorDF = pd.DataFrame(authorData)\n",
      "        getAuthorInfo(jsonLoads(d2), authorData, authorDF, count) \n",
      "        count +=1\n",
      "        if count%10000 == 0:\n",
      "            print \"done:\", float(count)/float(len(subData)) * 100.0\n",
      "    authorDFFinal = pd.DataFrame(authorData)\n",
      "    csvFileName = fileName.replace('.txt','.csv')\n",
      "    authorDFFinal.to_csv(\"../../../../../Desktop/authors2/\"+csvFileName)\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing file: medline14n0701.txt\n",
        "Start: Processing "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30001  records\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.3322222593\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.6644445185\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.9966667778\n",
        "Processing file: medline14n0702.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start: Processing "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30001  records\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.3322222593\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.6644445185\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.9966667778\n",
        "Processing file: medline14n0703.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start: Processing "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30001  records\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.3322222593\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.6644445185\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.9966667778\n",
        "Processing file: medline14n0704.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start: Processing "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30001  records\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.3322222593\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.6644445185\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.9966667778\n",
        "Processing file: medline14n0705.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start: Processing "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30001  records\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.3322222593\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.6644445185\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.9966667778\n",
        "Processing file: medline14n0706.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start: Processing "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30001  records\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.3322222593\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.6644445185\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.9966667778\n",
        "Processing file: medline14n0707.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start: Processing "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30001  records\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33.3322222593\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.6644445185\n",
        "done:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99.9966667778\n",
        "Processing file: medline14n0708.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start: Processing "
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import pandas as pd\n",
      "#authorDFFinal = pd.DataFrame(authorData)\n",
      "#print authorDFFinal.head(10)\n",
      "#print \"\\n\"\n",
      "#duplicate = authorData[0]\n",
      "#print duplicate\n",
      "#testJournals = authorDFFinal[authorDFFinal['author'] == 'jshildreth'].journals\n",
      "#The list of all journals are located below in the panda dataframe\n",
      "#print testJournals.tolist()[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#authorDFFinal.to_csv(\"../../../../../Desktop/authors/medline14n0685.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
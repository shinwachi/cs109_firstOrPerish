{
 "metadata": {
  "name": "",
<<<<<<< HEAD
  "signature": "sha256:6f20b209e4e1c49938c51fb1de44b3d6d083ab46969fa5741026d8f3b0d879aa"
=======
  "signature": "sha256:1b5510d48160f5e2e4a1e43bb9ee8c190f5625cb5e4d4998fe16fea335e5ab64"
>>>>>>> 04aac9927541c02500cb319d35653d8803a00da8
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gzip, json, csv, os\n",
      "import ast\n",
      "from datetime import timedelta, date\n",
      "\n",
      "\n",
      "#infileDirPath = '../../../../../Dropbox/cs109_datasci_share_2/authout/'\n",
      "infileDirPath = '../../../../../Desktop/'\n",
      "\n",
      "allFiles = []\n",
      "for file in os.listdir(infileDirPath):\n",
      "    if file.endswith(\"txt.gz\"):\n",
      "        allFiles.append(file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#new\n",
      "print allFiles[:1]\n",
      "staticRow =''\n",
      "for signFile in allFiles[:1]:\n",
      "    signFile = infileDirPath + signFile\n",
      "    print signFile\n",
      "    outfile = gzip.open( signFile, 'r')\n",
      "    reader = csv.reader(outfile)\n",
      "    print reader\n",
      "    count = 0\n",
      "#    mydict = dict((rows[0],rows[2]) for rows in reader)\n",
      "    for rows in reader:\n",
      "        count += 1\n",
      "        if count == 4:\n",
      "            break\n",
      "        print rows[0]\n",
      "        print rows[2]\n",
      "        mydict = dict(author = rows[0] ,\n",
      "                      files=rows[2]\n",
      "                      )\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['filtered2.txt.gz']\n",
        "../../../../../Desktop/filtered2.txt.gz\n",
        "<_csv.reader object at 0x104a3d7c0>\n",
        "\n",
        "[]\n",
        "0_s.heyns\n",
        "[{'affiliation': '', 'nlmuniqueid': '17930050R', 'authPos': 1, 'authCount': 1, 'year': '1959'}]\n",
        "2_s.collins\n",
        "[{'affiliation': '', 'nlmuniqueid': '0400714', 'authPos': 1, 'authCount': 1, 'year': '1976'}]\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#new\n",
      "authorLocFiles = {}\n",
      "# This block of code figures out what authors should be grepped for and what files that author is located in\n",
      "# this block takes the longest of out of the three to run for a given author\n",
      "for oneFile in allFiles[:1]:\n",
      "    fileLocation = infileDirPath + oneFile\n",
      "    outfile = gzip.open( fileLocation, 'r')\n",
      "    reader = csv.reader(outfile)\n",
      "    count = 0\n",
      "    for row in reader:\n",
      "        count += 1\n",
      "        #This is is the limit\n",
      "        if count == 1000:\n",
      "            break\n",
      "        author = row[0]\n",
      "        if author not in authorLocFiles and not author == '':\n",
      "            authorLocFiles[author] = []\n",
      "            try:\n",
      "                locationInfo = dict(\n",
      "                    files = row[2]\n",
      "                    )\n",
      "                #print locationInfo\n",
      "                authorLocFiles[author].append(locationInfo)\n",
      "            except:\n",
      "                print \"Exception: \", author\n",
      "#new\n",
      "#This funciton calculates all summary Stats\n",
      "def summaryDictionary(allJournals):\n",
      "    ffay = 3000\n",
      "    flay = 3000\n",
      "    laay = 0\n",
      "    tfap = 0\n",
      "    tlap = 0\n",
      "    taap = 0\n",
      "\n",
      "    for entry in allJournals:\n",
      "        dictEn = dict(entry)\n",
      "        #print \"DictEN: \" ,dictEn\n",
      "        year = ''\n",
      "        year = str(dictEn['year'])\n",
      "        if not year == '':\n",
      "            year = float(year)\n",
      "            if year > laay:\n",
      "                laay = year\n",
      "        if dictEn['authPos'] == 1:\n",
      "            tfap += 1\n",
      "            if year < ffay:\n",
      "                ffay = year\n",
      "        elif dictEn['authPos'] == dictEn['authCount']:\n",
      "            tlap += 1\n",
      "            if year < flay:\n",
      "                flay = year\n",
      "        \n",
      "        taap +=1\n",
      "    tcl = abs(laay-ffay)\n",
      "    fcl = abs(laay -flay)\n",
      "    scl = abs(tcl - flay)\n",
      "    tcl2 = scl + fcl\n",
      "    \n",
      "    #Can't divide by 0\n",
      "    #change defaults here if they are not changed from above\n",
      "    if scl == 0:\n",
      "        scl = 1\n",
      "    if tcl == 0:\n",
      "        tcl = 1\n",
      "    \n",
      "    summary = dict(\n",
      "            ffay   = ffay,\n",
      "            flay   = flay,\n",
      "            laay   = laay,\n",
      "            tfap   = tfap,\n",
      "            tlap   = tlap,\n",
      "            taap   = taap,\n",
      "            tcl   = tcl,\n",
      "            fcl   = fcl,\n",
      "            scl   = scl,\n",
      "            tcl2  = tcl2,\n",
      "            frqfa = tfap/scl,\n",
      "            frqta = taap/tcl,\n",
      "\n",
      "        )\n",
      "    return summary\n",
      "\n",
      "allJournalsNew = []\n",
      "for oneAuthor in authorLocFiles:\n",
      "    #try:\n",
      "    #print \"\\n\" + oneAuthor\n",
      "    strings = authorLocFiles[oneAuthor]\n",
      "    for journal in strings:\n",
      "        journals = journal['files']\n",
      "        try:\n",
      "            journals = ast.literal_eval(journals)\n",
      "            allJournalsNew = allJournalsNew + journals\n",
      "        except:\n",
      "            print \"Exception: Bad Data for author, \" + oneAuthor\n",
      "        #print allJournalsNew\n",
      "    sumData = summaryDictionary(allJournalsNew)\n",
      "        #print sumData\n",
      "\n",
      "#a_a.aarnisalo\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exception: Bad Data for author, a_a.adogu\n",
        "Exception: Bad Data for author, a_a.abbott\n",
        "Exception: Bad Data for author, a_a.al-meshari\n",
        "Exception: Bad Data for author, a_a.amato"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.al-shawaf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.andreev\n",
        "Exception: Bad Data for author, a_a.anosov"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.ali\n",
        "Exception: Bad Data for author, a_a.amer\n",
        "Exception: Bad Data for author, a_a.allen"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.ahmed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.ajayi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.al-ghoury\n",
        "Exception: Bad Data for author, a_a.al-jabri"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.acosta\n",
        "Exception: Bad Data for author, a_a.al-shammari\n",
        "Exception: Bad Data for author, a_a.ariyo"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a.aarnink\n",
        "Exception: Bad Data for author, a_a.al-sulami"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.abdul aziz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.abu shanab"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.andreev-andrievskii\n",
        "Exception: Bad Data for author, a_a.arzamastsev"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.al saigh\n",
        "Exception: Bad Data for author, a_a.adeniyi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.alcivar"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.alekseev\n",
        "Exception: Bad Data for author, a_a.argyriou"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.alhubaishi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.aguirre\n",
        "Exception: Bad Data for author, a_a.adeleke"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.alaiya\n",
        "Exception: Bad Data for author, a_a.abdulla"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.al-emad"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a.aabas\n",
        "Exception: Bad Data for author, a.aamodt\n",
        "Exception: Bad Data for author, a_a.aldeeb"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.aarnisalo"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.adjei"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a.aaron"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.abdoh\n",
        "Exception: Bad Data for author, a_a.al-nahhas"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.abboud\n",
        "Exception: Bad Data for author, a_a.alfieri"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.alghamdi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.adgey"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a.aamiri"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a.aarabi\n",
        "Exception: Bad Data for author, a_a.amirzargar"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.adzhubei"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.acri"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.amis"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.aroutcheva"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exception: Bad Data for author, a_a.albrecht"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      " \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def summaryDictionary(allJournals):\n",
      "    ffay = 3000\n",
      "    flay = 3000\n",
      "    laay = 0\n",
      "    tfap = 0\n",
      "    tlap = 0\n",
      "    taap = 0\n",
      "\n",
      "    for entry in allJournals:\n",
      "        dictEn = dict(entry)\n",
      "        year = ''\n",
      "        year = str(dictEn['year'])\n",
      "        if not year == '':\n",
      "            year = float(year)\n",
      "            if year > laay:\n",
      "                laay = year\n",
      "        if dictEn['authPos'] == 1:\n",
      "            tfap += 1\n",
      "            if year < ffay:\n",
      "                ffay = year\n",
      "        elif dictEn['authPos'] == dictEn['authCount']:\n",
      "            tlap += 1\n",
      "            if year < flay:\n",
      "                flay = year\n",
      "        \n",
      "        taap +=1\n",
      "    tcl = abs(laay-ffay)\n",
      "    fcl = abs(laay -flay)\n",
      "    scl = abs(tcl - flay)\n",
      "    tcl2 = scl + fcl\n",
      "    \n",
      "    summary = dict(\n",
      "            ffa = ffay,\n",
      "            fla = flay,\n",
      "            laa = laay,\n",
      "            tfa = tfap,\n",
      "            tla = tlap,\n",
      "            taa = taap,\n",
      "            tcl = tcl,\n",
      "            fcl = fcl,\n",
      "            scl = sc,\n",
      "            tcl2 = tcl2\n",
      "        )\n",
      "return summary\n",
      "\n",
      "#print \"FFA: first first-author year: \", ffay\n",
      "#print \"FLA: first last-author year: \" , flay\n",
      "#print \"LAA: last all-author year: \", laay\n",
      "#print \"TFA: total first author paper: \", tfap\n",
      "#print \"TLA: total last author paper: \", tlap\n",
      "#print \"TAA: total paper (all author): \", taap\n",
      "#tcl = abs(laay-ffay)\n",
      "#print \"TCL: total career legth =  LAA - FFA: \", abs(tcl)\n",
      "#fcl = abs(laay -flay)\n",
      "#print \"FCL: faculty career length = LAA - FLA: \", abs(fcl)\n",
      "#scl = abs(tcl - flay)\n",
      "#print \"SCL: non-faculty scientist career length = TLA-FCL: \", abs(scl)\n",
      "#tcl2 = scl + fcl\n",
      "#print \"TCL2: total career length = SCL + FCL: \" , abs(tcl2)\n",
      "#print \"FRQFA: frequency of first author = TFA/SCL: \", tfap/scl\n",
      "#print \"FRQTA: frequency of all authorship = TAA/TCL: \", taap/tcl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "41\n",
        "['affiliation', 'nlmuniqueid', 'authPos', 'authCount', 'year']\n",
        "FFA: first first-author year:  1879.0\n",
        "FLA: first last-author year:  1968.0\n",
        "LAA: last all-author year:  1998.0\n",
        "TFA: total first author paper:  28\n",
        "TLA: total last author paper:  6\n",
        "TAA: total paper (all author):  41\n",
        "TCL: total career legth =  LAA - FFA:  119.0\n",
        "FCL: faculty career length = LAA - FLA:  30.0\n",
        "SCL: non-faculty scientist career length = TLA-FCL:  1849.0\n",
        "TCL2: total career length = SCL + FCL:  1879.0\n",
        "FRQFA: frequency of first author = TFA/SCL:  0.0151433207139\n",
        "FRQTA: frequency of all authorship = TAA/TCL:  0.344537815126\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
<<<<<<< HEAD
      "import gzip, json, csv, os\n",
      "\n",
      "# infileDirPath = '../../../../../Dropbox/cs109_datasci_share_2/authout/'\n",
      "infileDirPath = '/vagrant/cs109_firstOrPerish/data_munging/authorOut/authout/'\n",
      "allFiles = [f for f in os.listdir(infileDirPath) if f.endswith(\".gz\")]\n",
      "len(allFiles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "746"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "authorLocFiles = {}\n",
      "\n",
      "for oneFile in allFiles[:1]:\n",
      "    fileLocation = infileDirPath + oneFile\n",
      "    reader  = csv.reader(gzip.open( fileLocation, 'r'))\n",
      "    for count, row in enumerate(reader, start=1):\n",
      "        if count == 2:\n",
      "            break\n",
      "        author = row[0]\n",
      "        if author not in authorLocFiles:\n",
      "            cmd = \"zgrep '\"+ author+\"' \" +  infileDirPath +  \"auth_medline14n* | cut -d':' -f1\"\n",
      "            authorLocFiles[author] = []\n",
      "\n",
      "            try:\n",
      "                fp = os.popen(cmd)\n",
      "                filesForAuthor = fp.read()\n",
      "                fp.close()\n",
      "                filesArry = filesForAuthor.split('\\n')\n",
      "                locationInfo = dict(\n",
      "                    files = filesArry\n",
      "                    )\n",
      "                #print locationInfo\n",
      "                authorLocFiles[author].append(locationInfo)\n",
      "            except:\n",
      "                print \"Exception: \" + cmd\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exception: zgrep 'l_b.lopez-hernandez' /vagrant/cs109_firstOrPerish/data_munging/authorOut/authout/auth_medline14n* | cut -d':' -f1\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = allFiles[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "'auth_medline14n0641.csv.gz'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filepath = os.path.join(infileDirPath, x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filepath"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'/vagrant/cs109_firstOrPerish/data_munging/authorOut/authout/auth_medline14n0641.csv.gz'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "pattern = re.compile(\"auth_medline14n(\\d+).csv.gz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern.findall(filepath)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "'0641'"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find all first authors\n",
      "reader  = csv.reader(gzip.open( fileLocation, 'r'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [x for x in reader]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "133132"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "['l_b.lopez-hernandez',\n",
        " \"[{'affiliation': 'Division de Genetica, Centro de Investigacion Biomedica de Occidente, Instituto Mexicano del Seguro Social, Mexico DF, Mexico. mones17@yahoo.com', 'nlmuniqueid': '7706841', 'authPos': 1, 'authCount': 3, 'year': ''}]\"]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "auths = set()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for authKey, article in data:\n",
      "    if \"'authPos': 1,\" in article:\n",
      "        auths.add(authKey)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(auths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "28630"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gzip, json, csv, os\n",
      "\n",
      "\n",
      "\n",
      "# infileDirPath = '../../../../../Dropbox/cs109_datasci_share_2/authout/'\n",
      "infileDirPath = '/vagrant/cs109_firstOrPerish/data_munging/authorOut/authout/'\n",
      "allFiles = [f for f in os.listdir(infileDirPath) if f.endswith(\".gz\")]\n",
      "print \"total number of files:\", len(allFiles)\n",
      "\n",
      "# scan first for all first authors\n",
      "fst_auths = set()\n",
      "for idx, filename in enumerate(allFiles):\n",
      "    if idx%50 == 0:\n",
      "        print idx, filename\n",
      "    filepath = os.path.join(infileDirPath, filename)\n",
      "    for authKey, article in  csv.reader(gzip.open( filepath)):\n",
      "        # hacky part: search for a specific string for hint of 1st author\n",
      "        if \"'authPos': 1,\" in article:\n",
      "            fst_auths.add(authKey)\n",
      "# this process actually took less than 15 minutes on a virtual machine, so it's pretty fast\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total number of files: 746\n",
        "0 auth_medline14n0641.csv.gz\n",
        "50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0691.csv.gz\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0741.csv.gz\n",
        "150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0578.csv.gz\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0628.csv.gz\n",
        "250"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0464.csv.gz\n",
        "300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0514.csv.gz\n",
        "350"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0350.csv.gz\n",
        "400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0400.csv.gz\n",
        "450"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0236.csv.gz\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0286.csv.gz\n",
        "550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0122.csv.gz\n",
        "600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0172.csv.gz\n",
        "650"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0010.csv.gz\n",
        "700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0060.csv.gz\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save the first author list (using gzip instead of zip, since it is less of a pain to deal with)\n",
      "outfilepath = \"/vagrant/cs109_firstOrPerish/data_munging/firstAuthorKeys.csv.gz\"\n",
      "f = gzip.open(outfilepath, 'wb')\n",
      "writer = csv.writer(f, dialect=csv.excel)\n",
      "\n",
      "for authKey in list(fst_auths):\n",
      "    writer.writerow([authKey])\n",
      "f.close()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(fst_auths)\n",
      "# only 5 million authors to deal with!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "4942347"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "auth_files = {}\n",
      "for fa in fst_auths:\n",
      "    auth_files[fa] = set()\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import re\n",
      "# usage: pattern.findall(filepath)[0]\n",
      "pattern = re.compile(\"auth_medline14n(\\d+).csv.gz\")\n",
      "\n",
      "\n",
      "# scan next for files to look in\n",
      "for idx, filename in enumerate(allFiles):\n",
      "    if idx%50 == 0:\n",
      "        print idx, filename\n",
      "    \n",
      "    \n",
      "    # number index (saves memory vs strings)\n",
      "    fIdx = int(pattern.findall(filename)[0])\n",
      "    \n",
      "    filepath = os.path.join(infileDirPath, filename)\n",
      "    \n",
      "    \n",
      "    for authKey, _ in  csv.reader(gzip.open( filepath)):\n",
      "        # get any mention of author in the fst_authors\n",
      "#         if authKey in auth_files.keys(): <------------------ this takes forever.\n",
      "        try:\n",
      "            auth_files[authKey].add(fIdx)\n",
      "        except:\n",
      "            pass\n",
      "    # this process actually took less than 15 minutes on a virtual machine, so it's pretty fast\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 auth_medline14n0641.csv.gz\n",
        "50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0691.csv.gz\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0741.csv.gz\n",
        "150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " auth_medline14n0578.csv.gz\n",
        "200"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "# save the first author list (using gzip instead of zip, since it is less of a pain to deal with)\n",
      "outfilepath = \"/vagrant/cs109_firstOrPerish/data_munging/authorFileLists.csv.gz\"\n",
      "f = gzip.open(outfilepath, 'wb')\n",
      "writer = csv.writer(f, dialect=csv.excel)\n",
      "\n",
      "for authKey, fileList in auth_files:\n",
      "    writer.writerow([authKey] + list(fileList))\n",
      "\n",
      "f.close()\n",
      "\n",
      "\n",
      "\n"
=======
      "\"\"\"\n",
      "['affiliation', 'nlmuniqueid', 'authPos', 'authCount', 'year']\n",
      "\n",
      "    FFA: first first-author year\n",
      "    FLA: first last-author year\n",
      "    LAA: last all-author year\n",
      "\n",
      "\n",
      "    TFA: total first author paper\n",
      "    TLA: total last author paper\n",
      "    TAA: total paper (all author)\n",
      "\n",
      "\n",
      "    TCL: total career legth =  LAA - FFA\n",
      "    FCL: faculty career length = LAA - FLA\n",
      "    SCL: non-faculty scientist career length = TCL-FCL\n",
      "    TCL: total career length = SCL + FCL\n",
      "    FRQFA: frequency of first author = TFA/SCL\n",
      "    FRQTA: frequency of all authorship = TAA/TCL\n",
      "\"\"\""
>>>>>>> 04aac9927541c02500cb319d35653d8803a00da8
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
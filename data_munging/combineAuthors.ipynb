{
 "metadata": {
  "name": "",
  "signature": "sha256:4baffb35c27e3b8f7feec932a110355bc79d23146a71fa67aae3ecacc980a5a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gzip, json, csv, os\n",
      "import ast\n",
      "from datetime import timedelta, date\n",
      "\n",
      "\n",
      "infileDirPath = '../../../../../Dropbox/cs109_datasci_share_2/authout/'\n",
      "\n",
      "allFiles = []\n",
      "for file in os.listdir(infileDirPath):\n",
      "    if file.endswith(\".gz\"):\n",
      "        allFiles.append(file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print allFiles[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['auth_medline14n0001.csv.gz', 'auth_medline14n0002.csv.gz', 'auth_medline14n0003.csv.gz', 'auth_medline14n0004.csv.gz', 'auth_medline14n0005.csv.gz', 'auth_medline14n0006.csv.gz', 'auth_medline14n0007.csv.gz', 'auth_medline14n0008.csv.gz', 'auth_medline14n0009.csv.gz', 'auth_medline14n0010.csv.gz']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "authorLocFiles = {}\n",
      "# This block of code figures out what authors should be grepped for and what files that author is located in\n",
      "# this block takes the longest of out of the three to run for a given author\n",
      "for oneFile in allFiles[:1]:\n",
      "    fileLocation = infileDirPath + oneFile\n",
      "    outfile = gzip.open( fileLocation, 'r')\n",
      "    reader = csv.reader(outfile)\n",
      "    count = 0\n",
      "    for row in reader:\n",
      "        count += 1\n",
      "        if count == 2:\n",
      "            break\n",
      "        author = row[0]\n",
      "        if author not in authorLocFiles:\n",
      "            cmd = \"zgrep '\"+ author+\"' \" +  infileDirPath +  \"auth_medline14n* | cut -d':' -f1\"\n",
      "            authorLocFiles[author] = []\n",
      "\n",
      "            try:\n",
      "                fp = os.popen(cmd)\n",
      "                filesForAuthor = fp.read()\n",
      "                fp.close()\n",
      "                filesArry = filesForAuthor.split('\\n')\n",
      "                locationInfo = dict(\n",
      "                    files = filesArry\n",
      "                    )\n",
      "                #print locationInfo\n",
      "                authorLocFiles[author].append(locationInfo)\n",
      "            except:\n",
      "                print \"Exception: \" + cmd\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print authorLocFile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This funciton calculates all summary Stats\n",
      "def summaryDictionary(allJournals):\n",
      "    ffay = 3000\n",
      "    flay = 3000\n",
      "    laay = 0\n",
      "    tfap = 0\n",
      "    tlap = 0\n",
      "    taap = 0\n",
      "\n",
      "    for entry in allJournals:\n",
      "        dictEn = dict(entry)\n",
      "        year = ''\n",
      "        year = str(dictEn['year'])\n",
      "        if not year == '':\n",
      "            year = float(year)\n",
      "            if year > laay:\n",
      "                laay = year\n",
      "        if dictEn['authPos'] == 1:\n",
      "            tfap += 1\n",
      "            if year < ffay:\n",
      "                ffay = year\n",
      "        elif dictEn['authPos'] == dictEn['authCount']:\n",
      "            tlap += 1\n",
      "            if year < flay:\n",
      "                flay = year\n",
      "        \n",
      "        taap +=1\n",
      "    tcl = abs(laay-ffay)\n",
      "    fcl = abs(laay -flay)\n",
      "    scl = abs(tcl - flay)\n",
      "    tcl2 = scl + fcl\n",
      "    \n",
      "    summary = dict(\n",
      "            ffa   = ffay,\n",
      "            fla   = flay,\n",
      "            laa   = laay,\n",
      "            tfa   = tfap,\n",
      "            tla   = tlap,\n",
      "            taa   = taap,\n",
      "            tcl   = tcl,\n",
      "            fcl   = fcl,\n",
      "            scl   = scl,\n",
      "            tcl2  = tcl2,\n",
      "            frqfa = tfap/scl,\n",
      "            frqta = taap/tcl,\n",
      "\n",
      "        )\n",
      "    return summary\n",
      "\n",
      "\n",
      "files = authorLocFiles['a_h.young'][0]\n",
      "\n",
      "allJournals = []\n",
      "# this fetches all the files and gets aggregates all the journals into one array for processing in next block of code.\n",
      "for oneFile in files:\n",
      "    print oneFile\n",
      "    if not oneFile == '':\n",
      "        oneOutfile = gzip.open( oneFile, 'r')\n",
      "        oneReader = csv.reader(oneOutfile)\n",
      "        mydict = dict((rows[0],rows[1]) for rows in oneReader)\n",
      "        strings = mydict['a_h.young']\n",
      "#allJournals = allJournals + mydict['a_h.young']\n",
      "        strings = ast.literal_eval(strings)\n",
      "        allJournals = allJournals + strings\n",
      "summary = summaryDictionary(allJournals)\n",
      "print summary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0001.csv.gz\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0002.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0065.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0088.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0092.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0093.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0102.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0157.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0238.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0311.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0319.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0328.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0330.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0336.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0342.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0347.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0358.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0359.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0360.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0374.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0389.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0390.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0405.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../../../../../Dropbox/cs109_datasci_share_2/authout/auth_medline14n0421.csv.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'scl': 1849.0, 'tcl2': 1879.0, 'tfa': 28, 'laa': 1998.0, 'frqta': 0.3445378151260504, 'tla': 6, 'taa': 41, 'fla': 1968.0, 'tcl': 119.0, 'frqfa': 0.015143320713899405, 'fcl': 30.0, 'ffa': 1879.0}\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def summaryDictionary(allJournals):\n",
      "    ffay = 3000\n",
      "    flay = 3000\n",
      "    laay = 0\n",
      "    tfap = 0\n",
      "    tlap = 0\n",
      "    taap = 0\n",
      "\n",
      "    for entry in allJournals:\n",
      "        dictEn = dict(entry)\n",
      "        year = ''\n",
      "        year = str(dictEn['year'])\n",
      "        if not year == '':\n",
      "            year = float(year)\n",
      "            if year > laay:\n",
      "                laay = year\n",
      "        if dictEn['authPos'] == 1:\n",
      "            tfap += 1\n",
      "            if year < ffay:\n",
      "                ffay = year\n",
      "        elif dictEn['authPos'] == dictEn['authCount']:\n",
      "            tlap += 1\n",
      "            if year < flay:\n",
      "                flay = year\n",
      "        \n",
      "        taap +=1\n",
      "    tcl = abs(laay-ffay)\n",
      "    fcl = abs(laay -flay)\n",
      "    scl = abs(tcl - flay)\n",
      "    tcl2 = scl + fcl\n",
      "    \n",
      "    summary = dict(\n",
      "            ffa = ffay,\n",
      "            fla = flay,\n",
      "            laa = laay,\n",
      "            tfa = tfap,\n",
      "            tla = tlap,\n",
      "            taa = taap,\n",
      "            tcl = tcl,\n",
      "            fcl = fcl,\n",
      "            scl = sc,\n",
      "            tcl2 = tcl2\n",
      "        )\n",
      "return summary\n",
      "\n",
      "#print \"FFA: first first-author year: \", ffay\n",
      "#print \"FLA: first last-author year: \" , flay\n",
      "#print \"LAA: last all-author year: \", laay\n",
      "#print \"TFA: total first author paper: \", tfap\n",
      "#print \"TLA: total last author paper: \", tlap\n",
      "#print \"TAA: total paper (all author): \", taap\n",
      "#tcl = abs(laay-ffay)\n",
      "#print \"TCL: total career legth =  LAA - FFA: \", abs(tcl)\n",
      "#fcl = abs(laay -flay)\n",
      "#print \"FCL: faculty career length = LAA - FLA: \", abs(fcl)\n",
      "#scl = abs(tcl - flay)\n",
      "#print \"SCL: non-faculty scientist career length = TLA-FCL: \", abs(scl)\n",
      "#tcl2 = scl + fcl\n",
      "#print \"TCL2: total career length = SCL + FCL: \" , abs(tcl2)\n",
      "#print \"FRQFA: frequency of first author = TFA/SCL: \", tfap/scl\n",
      "#print \"FRQTA: frequency of all authorship = TAA/TCL: \", taap/tcl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "41\n",
        "['affiliation', 'nlmuniqueid', 'authPos', 'authCount', 'year']\n",
        "FFA: first first-author year:  1879.0\n",
        "FLA: first last-author year:  1968.0\n",
        "LAA: last all-author year:  1998.0\n",
        "TFA: total first author paper:  28\n",
        "TLA: total last author paper:  6\n",
        "TAA: total paper (all author):  41\n",
        "TCL: total career legth =  LAA - FFA:  119.0\n",
        "FCL: faculty career length = LAA - FLA:  30.0\n",
        "SCL: non-faculty scientist career length = TLA-FCL:  1849.0\n",
        "TCL2: total career length = SCL + FCL:  1879.0\n",
        "FRQFA: frequency of first author = TFA/SCL:  0.0151433207139\n",
        "FRQTA: frequency of all authorship = TAA/TCL:  0.344537815126\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "['affiliation', 'nlmuniqueid', 'authPos', 'authCount', 'year']\n",
      "\n",
      "    FFA: first first-author year\n",
      "    FLA: first last-author year\n",
      "    LAA: last all-author year\n",
      "\n",
      "\n",
      "    TFA: total first author paper\n",
      "    TLA: total last author paper\n",
      "    TAA: total paper (all author)\n",
      "\n",
      "\n",
      "    TCL: total career legth =  LAA - FFA\n",
      "    FCL: faculty career length = LAA - FLA\n",
      "    SCL: non-faculty scientist career length = TCL-FCL\n",
      "    TCL: total career length = SCL + FCL\n",
      "    FRQFA: frequency of first author = TFA/SCL\n",
      "    FRQTA: frequency of all authorship = TAA/TCL\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}